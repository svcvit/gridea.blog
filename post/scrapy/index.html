<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Scrapy 使用教程 | 小众需求</title>
<meta name="description" content="一些很小众的需求，往往需要自己找答案。" />
<link rel="shortcut icon" href="https://svcvit.github.io/favicon.ico?v=1572141060769">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://svcvit.github.io/styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-148510687-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-148510687-1');
</script>


  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://svcvit.github.io">
  <img class="avatar" src="https://svcvit.github.io/images/avatar.png?v=1572141060769" alt="">
  </a>
  <h1 class="site-title">
    小众需求
  </h1>
  <p class="site-description">
    一些很小众的需求，往往需要自己找答案。
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Scrapy 使用教程
            </h2>
            <div class="post-info">
              <span>
                2019-09-20
              </span>
              <span>
                3 min read
              </span>
              
                <a href="https://svcvit.github.io/tag/A2ndwgKym" class="post-tag">
                  # python
                </a>
              
            </div>
            
              <img class="post-feature-image" src="https://svcvit.github.io/post-images/scrapy.png" alt="">
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h3 id="创建项目">创建项目</h3>
<p><code>scrapy startproject project_name</code></p>
<h3 id="创建爬虫">创建爬虫</h3>
<p><code>scrapy genspider web hostname</code></p>
<h3 id="定义数据">定义数据</h3>
<p>这里定义需要保存的数据，编辑<code>items.py</code></p>
<pre><code class="language-python">class InfoItem(scrapy.Item):
    title = scrapy.Field
    link = scrapy.Field
    desc  = scrapy.Field
</code></pre>
<h3 id="编辑-webpy">编辑 web.py</h3>
<pre><code class="language-python">from tutorial.items import InfoItem

class WebSpider(scrapy.Spider):
    name = &quot;web&quot;
    allowed_domains = [&quot;hostname&quot;]
    start_urls = [
        &quot;http://www.chinadrugtrials.org.cn/eap/clinicaltrials.searchlist&quot;
    ]

    def parse(self, response):
        item = InfoItem()
        item['title'] = response.xpath('//*[@id=&quot;searchfrm&quot;]/div/div[3]/div[1]/a[1]/text()').extract()[0]
        yield item
</code></pre>
<h3 id="或者再写一个爬虫">或者再写一个爬虫</h3>
<pre><code class="language-python">
class DetailSpider(scrapy.Spider):
    name = 'detail'
    allowed_domains = ['www.chinadrugtrials.org.cn']
    
    def start_requests(self):
        url = 'http://www.chinadrugtrials.org.cn/eap/clinicaltrials.searchlistdetail'
        for i in range(0,9058):
            params = {'currentpage':'',
                    'keywords':&quot;&quot;,
                    'pagesize':'20',
                    'sort':'desc',
                    'sort2':'desc',
                    'rule':'CTR',
                    'reg_no':'CTR'}
            params['ckm_index'] = str(i+1)
            yield scrapy.FormRequest(url,method=&quot;POST&quot;,formdata =params,callback=self.parse)

    def parse(self, response):
        # 保存文件
        filename = response.xpath('/html/body/div[1]/table/tbody/tr[2]/td/div[2]/div/div[2]/div[1]/div[3]/table/tr[1]/td[2]/text()').extract()[0]
        print(filename)
        with open(&quot;html/&quot;+filename+&quot;.html&quot;, 'wb') as f:
            f.write(response.body)
</code></pre>
<h3 id="存储数据到-pgsql">存储数据到 pgsql</h3>
<p>编辑pipelines.py文件</p>
<pre><code class="language-python">from twisted.enterprise import adbapi 
import psycopg2

class detail2Pipeline(object):
    @classmethod
    def from_settings(cls,settings):#名称固定 会被scrapy调用 直接可用setting的值
        db = settings['MYSQL_DB_NAME']
        host = settings['MYSQL_HOST']
        port = settings['MYSQL_PORT']
        user = settings['MYSQL_USER']
        passwd = settings['MYSQL_PASSWORD']
        #创建连接池对象，用pymysql访问数据库
        dbpool = adbapi.ConnectionPool(&quot;psycopg2&quot;,host = host,port = port, database= db,user=user,password=passwd)
        return cls(dbpool)

    def __init__(self,dbpool):
        self.dbpool=dbpool

    def process_item(self, item, spider):
        #去调用insert_db函数
        self.dbpool.runInteraction(self.insert_db,item)
        return item

    def insert_db(self, tx, item):
        values = (
        item[&quot;Registrationd_number&quot;] ,
        item[&quot;Testd_condition&quot;] ,
        item[&quot;Bidderd_Contact&quot;] ,
        item[&quot;Dated_ofd_firstd_publicd_announcement&quot;] ,
        item[&quot;Named_ofd_applicant&quot;]
        )
        try:
            sql = 'INSERT INTO &quot;DetailTrial&quot; (&quot;Registrationd_number&quot;,&quot;Testd_condition&quot;,&quot;Bidderd_Contact&quot;,&quot;Dated_ofd_firstd_publicd_announcement&quot;,&quot;Named_ofd_applicant&quot;) VALUES (%s,%s,%s,%s,%s)'
            tx.execute(sql, values)
            print(&quot;数据插入成功&quot;)
        except Exception as e:
            print('数据插入错误:', e)

    def close_spider(self,spider):
        self.dbpool.close()
</code></pre>
<h3 id="执行爬虫">执行爬虫</h3>
<p>将数据输出到json文件<br>
<code>scrapy crawl web -o items.json</code></p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE">创建项目</a></li>
<li><a href="#%E5%88%9B%E5%BB%BA%E7%88%AC%E8%99%AB">创建爬虫</a></li>
<li><a href="#%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE">定义数据</a></li>
<li><a href="#%E7%BC%96%E8%BE%91-webpy">编辑 web.py</a></li>
<li><a href="#%E6%88%96%E8%80%85%E5%86%8D%E5%86%99%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB">或者再写一个爬虫</a></li>
<li><a href="#%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E5%88%B0-pgsql">存储数据到 pgsql</a></li>
<li><a href="#%E6%89%A7%E8%A1%8C%E7%88%AC%E8%99%AB">执行爬虫</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://svcvit.github.io/post/LEDE">
              <h3 class="post-title">
                如何让你的小白朋友和你一样科学上网
              </h3>
            </a>
          </div>
        

        
          
            <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>

<div id="gitalk-container"></div>

<script>

  var gitalk = new Gitalk({
    clientID: 'cc922052c37806ae1048',
    clientSecret: '279d4ad4cbcb7c8f9a96b86ab70bc128e4cb5b7f',
    repo: 'svcvit.github.io',
    owner: 'svcvit',
    admin: ['svcvit'],
    id: (location.pathname).substring(0, 49),      // Ensure uniqueness and length less than 50
    distractionFreeMode: false  // Facebook-like distraction free mode
  })

  gitalk.render('gitalk-container')

</script>

          

          
        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://svcvit.github.io/atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()

  let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

  // This should probably be throttled.
  // Especially because it triggers during smooth scrolling.
  // https://lodash.com/docs/4.17.10#throttle
  // You could do like...
  // window.addEventListener("scroll", () => {
  //    _.throttle(doThatStuff, 100);
  // });
  // Only not doing it here to keep this Pen dependency-free.

  window.addEventListener("scroll", event => {
    let fromTop = window.scrollY;

    mainNavLinks.forEach((link, index) => {
      let section = document.getElementById(decodeURI(link.hash).substring(1));
      let nextSection = null
      if (mainNavLinks[index + 1]) {
        nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
      }
      console.log('section.offsetHeight', section.offsetHeight);
      if (section.offsetTop <= fromTop) {
        if (nextSection) {
          if (nextSection.offsetTop > fromTop) {
            link.classList.add("current");
          } else {
            link.classList.remove("current");    
          }
        } else {
          link.classList.add("current");
        }
      } else {
        link.classList.remove("current");
      }
    });
  });

</script>

      </div>
    </div>
  </body>
</html>
